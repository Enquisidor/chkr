{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../data/rumor-citation.zip'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-a0e1cc738be3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mrumor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../data/rumor-citation.zip'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mrumor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprintdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.8_3.8.1729.0_x64__qbz5n2kfra8p0\\lib\\zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[0;32m   1249\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1250\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1251\u001b[1;33m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1252\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1253\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../data/rumor-citation.zip'"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "\n",
    "rumor = zipfile.ZipFile('../data/rumor-citation.zip', 'r')\n",
    "rumor.printdir()\n",
    "print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import io\n",
    "\n",
    "rumor_csvs = io.TextIOWrapper(rumor.open('emergent.csv')), io.TextIOWrapper(rumor.open('politifact.csv')), io.TextIOWrapper(rumor.open('snopes.csv'))\n",
    "\n",
    "import pandas as p\n",
    "\n",
    "rumor_dfs = [p.read_csv(rumor_csvs[0]), p.read_csv(rumor_csvs[1]), p.read_csv(rumor_csvs[2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rumor Citation Emergent:\n",
      "Index(['emergent_page', 'claim', 'claim_description', 'claim_label', 'tags',\n",
      "       'claim_source_domain', 'claim_course_url', 'date', 'body',\n",
      "       'page_domain', 'page_url', 'page_headline', 'page_position',\n",
      "       'page_shares', 'page_order'],\n",
      "      dtype='object')\n",
      "\n",
      "Rumor Citation Politifact:\n",
      "Index(['politifact_page', 'claim', 'claim_source', 'claim_citation',\n",
      "       'claim_label', 'date_published', 'researched_by', 'edited_by', 'tags',\n",
      "       'page_citation', 'page_url', 'page_is_first_citation'],\n",
      "      dtype='object')\n",
      "\n",
      "Rumor Citation Snopes:\n",
      "Index(['snopes_page', 'topic', 'claim', 'claim_label', 'date_published',\n",
      "       'date_updated', 'page_url', 'page_is_example', 'page_is_image_credit',\n",
      "       'page_is_archived', 'page_is_first_citation', 'tags'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print('\\nRumor Citation Emergent:')\n",
    "print(rumor_dfs[0].columns)\n",
    "print('\\nRumor Citation Politifact:')\n",
    "print(rumor_dfs[1].columns)\n",
    "print('\\nRumor Citation Snopes:')\n",
    "print(rumor_dfs[2].columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rumor Citation Emergent:\n",
      "(2145, 15)\n",
      "\n",
      "Rumor Citation Politifact:\n",
      "(2923, 12)\n",
      "\n",
      "Rumor Citation Snopes:\n",
      "(16865, 12)\n"
     ]
    }
   ],
   "source": [
    "print('\\nRumor Citation Emergent:')\n",
    "print(rumor_dfs[0].shape)\n",
    "print('\\nRumor Citation Politifact:')\n",
    "print(rumor_dfs[1].shape)\n",
    "print('\\nRumor Citation Snopes:')\n",
    "print(rumor_dfs[2].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "rumor_dfs[0].claim_description = rumor_dfs[0].claim_description.fillna('')\n",
    "rumor_dfs[0].tags = rumor_dfs[0].tags.fillna('')\n",
    "rumor_dfs[0].page_headline = rumor_dfs[0].page_headline.fillna('')\n",
    "rumor_dfs[0] = rumor_dfs[0].dropna(subset=['page_domain'])\n",
    "rumor_dfs[0] = rumor_dfs[0].drop(['page_position'], axis=1)\n",
    "rumor_dfs[1].page_url = rumor_dfs[1].page_url.fillna('')\n",
    "rumor_dfs[2].topic = rumor_dfs[2].topic.fillna('')\n",
    "rumor_dfs[2].date_updated = rumor_dfs[2].date_updated.fillna('')\n",
    "rumor_dfs[2].page_url = rumor_dfs[2].page_url.fillna('')\n",
    "rumor_dfs[2].tags = rumor_dfs[2].tags.fillna('')\n",
    "rumor_dfs[2] = rumor_dfs[2].dropna(subset=['claim'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Rumor Citation Emergent:\n",
      "emergent_page          0\n",
      "claim                  0\n",
      "claim_description      0\n",
      "claim_label            0\n",
      "tags                   0\n",
      "claim_source_domain    0\n",
      "claim_course_url       0\n",
      "date                   0\n",
      "body                   0\n",
      "page_domain            0\n",
      "page_url               0\n",
      "page_headline          0\n",
      "page_shares            0\n",
      "page_order             0\n",
      "dtype: int64\n",
      "\n",
      "Rumor Citation Politifact:\n",
      "politifact_page           0\n",
      "claim                     0\n",
      "claim_source              0\n",
      "claim_citation            0\n",
      "claim_label               0\n",
      "date_published            0\n",
      "researched_by             0\n",
      "edited_by                 0\n",
      "tags                      0\n",
      "page_citation             0\n",
      "page_url                  0\n",
      "page_is_first_citation    0\n",
      "dtype: int64\n",
      "\n",
      "Rumor Citation Snopes:\n",
      "snopes_page               0\n",
      "topic                     0\n",
      "claim                     0\n",
      "claim_label               0\n",
      "date_published            0\n",
      "date_updated              0\n",
      "page_url                  0\n",
      "page_is_example           0\n",
      "page_is_image_credit      0\n",
      "page_is_archived          0\n",
      "page_is_first_citation    0\n",
      "tags                      0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('\\nRumor Citation Emergent:')\n",
    "print(rumor_dfs[0].isnull().sum())\n",
    "print('\\nRumor Citation Politifact:')\n",
    "print(rumor_dfs[1].isnull().sum())\n",
    "print('\\nRumor Citation Snopes:')\n",
    "print(rumor_dfs[2].isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       Daiane+DeJesus,DC+Toys+Collector,Porm,Sandy+Su...\n",
      "1       Daiane+DeJesus,DC+Toys+Collector,Porm,Sandy+Su...\n",
      "2       Daiane+DeJesus,DC+Toys+Collector,Porm,Sandy+Su...\n",
      "3       Australia,Food,Hamburger,McDonald's,Quarter+Po...\n",
      "4       Australia,Food,Hamburger,McDonald's,Quarter+Po...\n",
      "                              ...                        \n",
      "2140    Apple+Watch,Daisuke+Wakabayashi,Wall+Street+Jo...\n",
      "2141    Apple+Watch,Daisuke+Wakabayashi,Wall+Street+Jo...\n",
      "2142    Apple+Watch,Daisuke+Wakabayashi,Wall+Street+Jo...\n",
      "2143    Apple+Watch,Daisuke+Wakabayashi,Wall+Street+Jo...\n",
      "2144    Apple+Watch,Daisuke+Wakabayashi,Wall+Street+Jo...\n",
      "Name: tags, Length: 2144, dtype: object\n",
      "0       Fake news\n",
      "1       Fake news\n",
      "2       Fake news\n",
      "3       Fake news\n",
      "4       Fake news\n",
      "          ...    \n",
      "2918      History\n",
      "2919      History\n",
      "2920      History\n",
      "2921      History\n",
      "2922      History\n",
      "Name: tags, Length: 2923, dtype: object\n",
      "0                                              \n",
      "1                                              \n",
      "2                                              \n",
      "3                                              \n",
      "4                                              \n",
      "                          ...                  \n",
      "16860    politics,guatemala,donald-trump,mexico\n",
      "16861    politics,guatemala,donald-trump,mexico\n",
      "16862    politics,guatemala,donald-trump,mexico\n",
      "16863    politics,guatemala,donald-trump,mexico\n",
      "16864    politics,guatemala,donald-trump,mexico\n",
      "Name: tags, Length: 16862, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(rumor_dfs[0].tags)\n",
    "print(rumor_dfs[1].tags)\n",
    "print(rumor_dfs[2].tags)\n",
    "\n",
    "import re\n",
    "\n",
    "emergent_pattern = re.compile(re.escape(r'.*(+.*)*'))\n",
    "\n",
    "rumor_dfs[0].tags = rumor_dfs[0].tags.apply(lambda x: x.replace('+', \" \").split(','))\n",
    "rumor_dfs[1].tags = rumor_dfs[1].tags.apply(lambda x: x.replace('+', \" \").split(','))\n",
    "rumor_dfs[2].tags = rumor_dfs[2].tags.apply(lambda x: x.replace('+', \" \").split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unverified    857\n",
      "TRUE          737\n",
      "FALSE         550\n",
      "Name: claim_label, dtype: int64\n",
      "pants-fire     1110\n",
      "false           731\n",
      "barely-true     460\n",
      "half-true       244\n",
      "mostly-true     207\n",
      "true            171\n",
      "Name: claim_label, dtype: int64\n",
      "false           8765\n",
      "mfalse          3319\n",
      "mixture         2618\n",
      "true            1480\n",
      "mtrue            487\n",
      "undetermined     151\n",
      "legend            42\n",
      "Name: claim_label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(rumor_dfs[0].claim_label.value_counts())\n",
    "print(rumor_dfs[1].claim_label.value_counts())\n",
    "print(rumor_dfs[2].claim_label.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
